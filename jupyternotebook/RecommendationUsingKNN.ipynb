{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API request to get data\n",
    "import requests as req\n",
    "url = 'http://api.tvmaze.com/schedule?country=US'\n",
    "resp = req.get(url)\n",
    "response = resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert str datatype of response to list since json_normalize function from pandas\n",
    "#requires JSON array i.e. list of records\n",
    "import json\n",
    "data = json.loads(response)\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Module to load data as pandas dataframe using json_normalize function from pandas\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "df = json_normalize(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get shape of generated data frame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#List all column names to select relevant ones for further data processing\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get relevant columns from dataframe on which knn algorithm can be applied(feature selection)\n",
    "df_relevant = df[['name','id','show.name','show.genres','show.rating.average','show.type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print newly created data frame\n",
    "df_relevant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The reason to merge name column with show.name column was because\n",
    "some of the shows had repeated episodes. For example:- Abby Hatcher show had two entries with \n",
    "different episode names viz Afraid of Cats and Chef Curly. I needed unique names\n",
    "to identify nieghbours of an episode correctly which is why I merged the columns to\n",
    "generate unique names column'''\n",
    "df_relevant[\"full_name\"] = df_relevant[\"show.name\"].map(str) +\"-\"+ df_relevant[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the source columns from which full_name was generated\n",
    "df_relevant = df_relevant.drop(['name','show.name'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename column names of dataframe for ease of understanding\n",
    "renamed_columns_dictionary = {'show.genres': 'genres', \n",
    "                              'show.language': 'language',\n",
    "                              'show.rating.average':'rating',\n",
    "                              'show.type':'type'\n",
    "                             }\n",
    "df_relevant.rename(columns=renamed_columns_dictionary, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''There were many entries which had genres columns empty. We have the choice to\n",
    "substitute the empty values or drop them entirely'''\n",
    "df_relevant[df_relevant['genres'].str.len() == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping all columns whose genres column is empty for now \n",
    "#Adding relevant genres based on show type can be a better option later\n",
    "df_relevant = df_relevant.drop(df_relevant[df_relevant['genres'].str.len() == 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Considerable number of rows were removed\n",
    "df_relevant.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new copy for ease of use and keeping a backup just in case anything messes up ahead\n",
    "df = df_relevant.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for all null values in dataframe\n",
    "df.isnull().sum(axis = 0)\n",
    "#Ratings column had some null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check datatypes of all values\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill null values in rating column with median of all values in rating column\n",
    "df[\"rating\"].fillna(df[\"rating\"].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had to do label encoding for genres column. But pd.get_dummies function in \n",
    "pandas does not take list as row values due to which I had to convert them into\n",
    "string of comma separated values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genres'] = df['genres'].apply(lambda x: \",\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can get label encoded values from genres column using get_dummies fxn from pandas\n",
    "df[\"genres\"].str.get_dummies(sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating a new data frame to be used for generating model using knn. We are neglecting name and id column since they are not useful for finding neighbours. \n",
    "\"Genres\" and \"type\" column is label encoded while rating column is taken as it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_show_features = pd.concat([df[\"genres\"].str.get_dummies(sep=\",\"),\n",
    "                            pd.get_dummies(df[[\"type\"]]),\n",
    "                            df[[\"rating\"]]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_show_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ratings column has values from 0 to 10 while other columns have values from\n",
    "0 to 1 this can bias the distance metric in KNN because features containing bigger numbers will be weighted heavily while the other features will be discounted.\n",
    "So I ended up using MinMaxScaler from scikit-learn as it scales the values from 0â€“1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "tv_show_features = min_max_scaler.fit_transform(tv_show_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.round(tv_show_features,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we fit the KNN model from scikit learn to the data and calculate \n",
    "# the nearest neighbors for each distances.\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=6, algorithm='ball_tree').fit(tv_show_features)\n",
    "distances, indices = nbrs.kneighbors(tv_show_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper fucntions to get relevant predictions\n",
    "def get_index_from_name(name):\n",
    "    return df[df[\"full_name\"]==name].index.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_show_names = list(df.full_name.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_from_partial_name(partial):\n",
    "    for name in all_show_names:\n",
    "        if partial in name:\n",
    "            print(name,all_show_names.index(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_similar_tvshows(query=None,id=None):\n",
    "    if id:\n",
    "        for id in indices[id][1:]:\n",
    "            print(df.iloc[id][\"full_name\"])\n",
    "    if query:\n",
    "        found_id = get_index_from_name(query)\n",
    "        for id in indices[found_id][1:]:\n",
    "            print(df.iloc[id][\"full_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change values below as per full_name column values\n",
    "get_id_from_partial_name(\"Days of Our Lives-Ep. #13507\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_index_from_name(\"Days of Our Lives-Ep. #13507\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_similar_tvshows(\"Gotham-Trespassers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"full_name\"]==\"Gotham-Trespassers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showrecs=[\n",
    "\"Fam-Pilot\",\n",
    "\"The Big Bang Theory-The Propagation Proposition\",\n",
    "\"Mom-Hacky Sack and a Beautiful Experience\",\n",
    "\"Young Sheldon-A Tummy Ache and a Whale of a Metaphor\",\n",
    "\"The Orville-Home\"\n",
    "]\n",
    "\n",
    "df[df['full_name'].isin(showrecs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
